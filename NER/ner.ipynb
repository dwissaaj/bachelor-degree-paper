{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cahya/bert-base-indonesian-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"cahya/bert-base-indonesian-NER\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import TokenClassificationPipeline\n",
    "tokenclassifier = TokenClassificationPipeline(model=model,tokenizer=tokenizer,aggregation_strategy=\"simple\")\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"ner\",model=model,tokenizer=tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "predic = classifier(\"aji sedang makan ketoprak di jakarta\")\n",
    "dfa = pd.DataFrame(predic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "test2 = tokenclassifier(\"aji sedang makan ketoprak di jakarta\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9735748, 'index': 1, 'word': 'aji', 'start': 0, 'end': 3}, {'entity': 'I-EVT', 'score': 0.44471964, 'index': 4, 'word': 'ket', 'start': 17, 'end': 20}, {'entity': 'I-EVT', 'score': 0.5156463, 'index': 5, 'word': '##opr', 'start': 20, 'end': 23}, {'entity': 'B-GPE', 'score': 0.9946912, 'index': 8, 'word': 'jakarta', 'start': 29, 'end': 36}]\n",
      "[{'entity_group': 'PER', 'score': 0.9735748, 'word': 'aji', 'start': 0, 'end': 3}, {'entity_group': 'EVT', 'score': 0.48018295, 'word': 'ketopr', 'start': 17, 'end': 23}, {'entity_group': 'GPE', 'score': 0.9946912, 'word': 'jakarta', 'start': 29, 'end': 36}]\n"
     ]
    }
   ],
   "source": [
    "print(predic)\n",
    "print(test2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'entity_group': 'PER', 'score': 0.9735748, 'word': 'aji', 'start': 0, 'end': 3}, {'entity_group': 'EVT', 'score': 0.48018295, 'word': 'ketopr', 'start': 17, 'end': 23}, {'entity_group': 'GPE', 'score': 0.9946912, 'word': 'jakarta', 'start': 29, 'end': 36}], [{'entity_group': 'PER', 'score': 0.9801395, 'word': 'anies', 'start': 0, 'end': 5}, {'entity_group': 'ORG', 'score': 0.37239525, 'word': 'surabaya', 'start': 6, 'end': 14}, {'entity_group': 'PRD', 'score': 0.8045075, 'word': 'pecel lele', 'start': 15, 'end': 25}]]\n"
     ]
    }
   ],
   "source": [
    "testing = tokenclassifier([\"aji sedang makan ketoprak di jakarta\",\n",
    "                \"anies surabaya pecel lele\"])\n",
    "print(testing)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../Dataset/Book1.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "new_df = df.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tweet\n0      HOLYWINGS, kan mayoritas karyawannya Muslim? y...\n2      Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...\n3      Holywings Tutup 36 Outlet Seluruh Indonesia, T...\n11     Pihak berkuasa Indonesia menutup operasi bar d...\n13     Kasus seperti iklan Holywings mestinya adalah ...\n...                                                  ...\n20296  Itulah bunda.. memberi nama anak jangan asal-a...\n20303  Di Indonesia soalnya sdh bnyk sesuatu atau org...\n20304  Selamat PSM! \\nEWAKO!\\n\\n- METEORBET88 -\\n- ht...\n20317  Pagi2 nntn berita. Isinya penusukan, ricuh di ...\n20321  @manusialogis @yogaanggis @DR_online_shop8 @To...\n\n[3154 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOLYWINGS, kan mayoritas karyawannya Muslim? y...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Holywings Tutup 36 Outlet Seluruh Indonesia, T...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Pihak berkuasa Indonesia menutup operasi bar d...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Kasus seperti iklan Holywings mestinya adalah ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20296</th>\n      <td>Itulah bunda.. memberi nama anak jangan asal-a...</td>\n    </tr>\n    <tr>\n      <th>20303</th>\n      <td>Di Indonesia soalnya sdh bnyk sesuatu atau org...</td>\n    </tr>\n    <tr>\n      <th>20304</th>\n      <td>Selamat PSM! \\nEWAKO!\\n\\n- METEORBET88 -\\n- ht...</td>\n    </tr>\n    <tr>\n      <th>20317</th>\n      <td>Pagi2 nntn berita. Isinya penusukan, ricuh di ...</td>\n    </tr>\n    <tr>\n      <th>20321</th>\n      <td>@manusialogis @yogaanggis @DR_online_shop8 @To...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3154 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "['HOLYWINGS, kan mayoritas karyawannya Muslim? yaiyalah. Kan ini negeri mayoritas Muslim. Di balik jeruji penjara seluruh Indonesia pun, mayoritas isinya juga Muslim. Suka pada mendadak shaleh sih. Penjahat yang nggak Muslim, biasanya kabur ke Singapura atau China.  tks.',\n 'Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.co/cdhxC1Pxdg',\n 'Holywings Tutup 36 Outlet Seluruh Indonesia, Tersisa Outlet di Batam dan Manado\\nhttps://t.co/O3RGzwWbpi']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input = new_df['tweet'].values.tolist()\n",
    "raw_input[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data_ner = tokenclassifier(raw_input)\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "data_final_ner = pd.DataFrame(data_ner)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "data_final_ner.to_excel(\"../Dataset/NERDATA.xlsx\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from evalu\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}