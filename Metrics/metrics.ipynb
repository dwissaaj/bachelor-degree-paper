{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from evaluate import evaluator\n",
    "from transformers import AutoModelForSequenceClassification , pipeline ,AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset indonlu (C:\\Users\\W I N D O W S\\.cache\\huggingface\\datasets\\indonlu\\nerp\\1.0.0\\0a83b181cd831cd5d9c15ffe39f3be76af23407eba2c902bccca53fa905d68af)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"indonlu\",\"nerp\", split=\"validation\").shuffle().select(range(800))\n",
    "task_evaluator = evaluator(\"token-classification\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['tokens', 'ner_tags'],\n    num_rows: 800\n})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/800 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb94032c66984e9b9aceefb96ea4e4b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "c:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "models = [\n",
    "    \"cahya/bert-base-indonesian-NER\",\n",
    "]\n",
    "results = []\n",
    "for model in models:\n",
    "    results.append(\n",
    "        task_evaluator.compute(\n",
    "            model_or_pipeline=model, data=data, metric=\"seqeval\",input_column='tokens',label_column='ner_tags'\n",
    "            )\n",
    "        )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                              CRD  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              DAT  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              EVT  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.310126582278481, 'recall': 0.3...   \n\n                                                                              FAC  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              FNB  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              GPE  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              IND  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              LAW  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              LOC  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              MON  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                ...  \\\ncahya/bert-base-indonesian-NER  ...   \n\n                                                                              REG  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              TIM  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                                                                              WOA  \\\ncahya/bert-base-indonesian-NER  {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...   \n\n                               overall_precision overall_recall overall_f1  \\\ncahya/bert-base-indonesian-NER          0.016821       0.029219   0.021351   \n\n                               overall_accuracy total_time_in_seconds  \\\ncahya/bert-base-indonesian-NER         0.727234            196.770044   \n\n                               samples_per_second latency_in_seconds  \ncahya/bert-base-indonesian-NER            4.06566           0.245963  \n\n[1 rows x 29 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRD</th>\n      <th>DAT</th>\n      <th>EVT</th>\n      <th>FAC</th>\n      <th>FNB</th>\n      <th>GPE</th>\n      <th>IND</th>\n      <th>LAW</th>\n      <th>LOC</th>\n      <th>MON</th>\n      <th>...</th>\n      <th>REG</th>\n      <th>TIM</th>\n      <th>WOA</th>\n      <th>overall_precision</th>\n      <th>overall_recall</th>\n      <th>overall_f1</th>\n      <th>overall_accuracy</th>\n      <th>total_time_in_seconds</th>\n      <th>samples_per_second</th>\n      <th>latency_in_seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cahya/bert-base-indonesian-NER</th>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.310126582278481, 'recall': 0.3...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, '...</td>\n      <td>0.016821</td>\n      <td>0.029219</td>\n      <td>0.021351</td>\n      <td>0.727234</td>\n      <td>196.770044</td>\n      <td>4.06566</td>\n      <td>0.245963</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows Ã— 29 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, index=models)\n",
    "df[[\"overall_f1\", \"overall_accuracy\", \"total_time_in_seconds\", \"samples_per_second\", \"latency_in_seconds\"]]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df.to_excel(\"../Dataset/metrics ner voxpop 2.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
