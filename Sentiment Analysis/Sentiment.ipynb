{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'TextClassificationPipeline' has no attribute 'from_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m pretrained\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmdhugol/indonesia-bert-sentiment-classification\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mTextClassificationPipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m(pretrained)\n\u001B[0;32m      3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m  AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdone\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: type object 'TextClassificationPipeline' has no attribute 'from_pretrained'"
     ]
    }
   ],
   "source": [
    "pretrained= \"mdhugol/indonesia-bert-sentiment-classification\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained)\n",
    "tokenizer =  AutoTokenizer.from_pretrained(pretrained)\n",
    "print(\"done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "EagerTensor object has no attribute 'size'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m tokenizer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maji tersting model output\u001B[39m\u001B[38;5;124m\"\u001B[39m,return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1556\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1548\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1549\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1550\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1551\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1553\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1554\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1556\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1557\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1561\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1562\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1563\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1566\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1568\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1570\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32mc:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:966\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    964\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    965\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m input_ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 966\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m \u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m()\n\u001B[0;32m    967\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m inputs_embeds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    968\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m inputs_embeds\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[1;32mc:\\users\\w i n d o w s\\pycharmprojects\\pythonproject\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:440\u001B[0m, in \u001B[0;36mTensor.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[0;32m    437\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mravel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtranspose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreshape\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclip\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    438\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtolist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m}:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001B[39;00m\n\u001B[1;32m--> 440\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[0;32m    441\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;124m      If you are looking for numpy-related methods, please run the following:\u001B[39m\n\u001B[0;32m    443\u001B[0m \u001B[38;5;124m      from tensorflow.python.ops.numpy_ops import np_config\u001B[39m\n\u001B[0;32m    444\u001B[0m \u001B[38;5;124m      np_config.enable_numpy_behavior()\u001B[39m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;124m    \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n\u001B[0;32m    446\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(name)\n",
      "\u001B[1;31mAttributeError\u001B[0m: EagerTensor object has no attribute 'size'. \n        If you are looking for numpy-related methods, please run the following:\n        from tensorflow.python.ops.numpy_ops import np_config\n        np_config.enable_numpy_behavior()\n      "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "inputs = tokenizer(\"aji tersting model output\",return_tensors='tf')\n",
    "labels = torch.tensor([1]).unsqueeze(0)\n",
    "outputs = model(**inputs, labels=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_excel(\"../Dataset/Book1.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               tweet\n0  HOLYWINGS, kan mayoritas karyawannya Muslim? y...\n2  Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...\n3  Holywings Tutup 36 Outlet Seluruh Indonesia, T...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOLYWINGS, kan mayoritas karyawannya Muslim? y...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Holywings Tutup 36 Outlet Seluruh Indonesia, T...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset.drop_duplicates()\n",
    "df[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "raw_input = df['tweet'].values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.9968164563179016}]\n"
     ]
    }
   ],
   "source": [
    "classfier = pipeline(\"sentiment-analysis\",model=model,tokenizer=tokenizer)\n",
    "label_index = {'LABEL_0': 'POSITIVE', 'LABEL_1': 'NEUTRAL', 'LABEL_2': 'NEGATIVE'}\n",
    "result = classfier(\"anjing kau\")\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['HOLYWINGS, kan mayoritas karyawannya Muslim? yaiyalah. Kan ini negeri mayoritas Muslim. Di balik jeruji penjara seluruh Indonesia pun, mayoritas isinya juga Muslim. Suka pada mendadak shaleh sih. Penjahat yang nggak Muslim, biasanya kabur ke Singapura atau China.  tks.',\n 'Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.co/cdhxC1Pxdg',\n 'Holywings Tutup 36 Outlet Seluruh Indonesia, Tersisa Outlet di Batam dan Manado\\nhttps://t.co/O3RGzwWbpi']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = raw_input[:3]\n",
    "testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_2', 'score': 0.987440824508667}, {'label': 'LABEL_1', 'score': 0.9667484760284424}, {'label': 'LABEL_1', 'score': 0.9963110089302063}]\n"
     ]
    }
   ],
   "source": [
    "test2 = classfier(testing)\n",
    "print(test2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data = pd.DataFrame(test2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "data_sen = classfier(raw_input)\n",
    "print(\"done\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "data_sentiment = pd.DataFrame(data_sen)\n",
    "data_sentiment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(raw_input,columns=['tweet'])\n",
    "new_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  tweet    label     score\n0     HOLYWINGS, kan mayoritas karyawannya Muslim? y...  LABEL_2  0.987441\n1     Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...  LABEL_1  0.966748\n2     Holywings Tutup 36 Outlet Seluruh Indonesia, T...  LABEL_1  0.996311\n3     Pihak berkuasa Indonesia menutup operasi bar d...  LABEL_1  0.980567\n4     Kasus seperti iklan Holywings mestinya adalah ...  LABEL_2  0.974012\n...                                                 ...      ...       ...\n3149  Itulah bunda.. memberi nama anak jangan asal-a...  LABEL_2  0.970642\n3150  Di Indonesia soalnya sdh bnyk sesuatu atau org...  LABEL_2  0.956136\n3151  Selamat PSM! \\nEWAKO!\\n\\n- METEORBET88 -\\n- ht...  LABEL_1  0.952708\n3152  Pagi2 nntn berita. Isinya penusukan, ricuh di ...  LABEL_2  0.948720\n3153  @manusialogis @yogaanggis @DR_online_shop8 @To...  LABEL_1  0.934518\n\n[3154 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOLYWINGS, kan mayoritas karyawannya Muslim? y...</td>\n      <td>LABEL_2</td>\n      <td>0.987441</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hanya satu kata: Alhamdulillah.\\n\\nhttps://t.c...</td>\n      <td>LABEL_1</td>\n      <td>0.966748</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Holywings Tutup 36 Outlet Seluruh Indonesia, T...</td>\n      <td>LABEL_1</td>\n      <td>0.996311</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Pihak berkuasa Indonesia menutup operasi bar d...</td>\n      <td>LABEL_1</td>\n      <td>0.980567</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Kasus seperti iklan Holywings mestinya adalah ...</td>\n      <td>LABEL_2</td>\n      <td>0.974012</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3149</th>\n      <td>Itulah bunda.. memberi nama anak jangan asal-a...</td>\n      <td>LABEL_2</td>\n      <td>0.970642</td>\n    </tr>\n    <tr>\n      <th>3150</th>\n      <td>Di Indonesia soalnya sdh bnyk sesuatu atau org...</td>\n      <td>LABEL_2</td>\n      <td>0.956136</td>\n    </tr>\n    <tr>\n      <th>3151</th>\n      <td>Selamat PSM! \\nEWAKO!\\n\\n- METEORBET88 -\\n- ht...</td>\n      <td>LABEL_1</td>\n      <td>0.952708</td>\n    </tr>\n    <tr>\n      <th>3152</th>\n      <td>Pagi2 nntn berita. Isinya penusukan, ricuh di ...</td>\n      <td>LABEL_2</td>\n      <td>0.948720</td>\n    </tr>\n    <tr>\n      <th>3153</th>\n      <td>@manusialogis @yogaanggis @DR_online_shop8 @To...</td>\n      <td>LABEL_1</td>\n      <td>0.934518</td>\n    </tr>\n  </tbody>\n</table>\n<p>3154 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = pd.concat([new_df,data_sentiment],axis=1)\n",
    "data_final"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "data_final.to_excel(\"../Dataset/sentiment.xlsx\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}